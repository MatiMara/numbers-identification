import os
import cv2
import numpy as np
from tensorflow.keras import layers, models
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

def load_labels_from_file(label_file):
    if os.path.exists(label_file):
        with open(label_file, 'r') as file:
            lines = file.readlines()
            # Weź tylko pierwszą linię z pliku tekstowego
            label = list(map(float, lines[0].strip().split()))
        return label
    else:
        return None

# Dane z folderu
data_folder = r'C:\Users\mateu\Desktop\wykrywanie_rzeczy\dataset\images'
label_folder = r'C:\Users\mateu\Desktop\wykrywanie_rzeczy\dataset\labels'

image_files = [os.path.join(data_folder, file) for file in os.listdir(data_folder) if file.endswith('.png')]
label_files = [os.path.join(label_folder, file.replace('.png', '.txt')) for file in os.listdir(data_folder) if
               file.endswith('.png')]

images = []
labels = []

for image_file, label_file in zip(image_files, label_files):
    image = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE)
    image = cv2.resize(image, (256, 256))  # Wymiary wejściowe modelu

    # Wczytaj etykiety z pliku (jeśli istnieje)
    label_data = load_labels_from_file(label_file)

    # Dodaj obraz i etykietę tylko, jeśli plik etykiety istnieje
    if label_data is not None:
        images.append(image)
        labels.append(label_data)
    else:
        print(f"Pominięto: {image_file}, brak pliku z etykietami")

images = np.array(images) / 255.0
labels = np.array(labels)

# Podział na zbiór treningowy i testowy
train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, random_state=42)

# Zmiana kształtu danych dla warstw konwolucyjnych
train_images = train_images.reshape((train_images.shape[0], 256, 256, 1))
test_images = test_images.reshape((test_images.shape[0], 256, 256, 1))

# Definicja modelu z dwiema warstwami konwolucyjnymi i dodatkowymi zmianami
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(256, activation='relu'),  # Zwiększona liczba neuronów
    layers.Dropout(0.5),  # Dodany dropout
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(5, activation='linear')  # Zmiana liczby neuronów i funkcji aktywacji
])

# Kompilacja
model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])  # Zmiana funkcji straty

# Trenowanie
model.fit(train_images, train_labels, epochs=50)

# Ocena
test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)
print(f"\nDokładność testowa: {test_acc}")

# Zapisz model w określonym folderze
model_path = r'C:\Users\mateu\Desktop\wykrywanie_rzeczy\modele\nazwa_modelu.h5'
model.save(model_path)
print(f"Model został zapisany w: {model_path}")

# Wybierz zdjęcie do predykcji
chosen_image_path = r'C:\Users\mateu\Desktop\wykrywanie_rzeczy\dataset\images\55.png'
chosen_image = cv2.imread(chosen_image_path, cv2.IMREAD_GRAYSCALE)
chosen_image = cv2.resize(chosen_image, (256, 256))
chosen_image = np.expand_dims(chosen_image, axis=-1)
chosen_image = np.expand_dims(chosen_image, axis=0)

# Przewiduj za pomocą modelu
predictions = model.predict(chosen_image)

# Wypisz przeskalowane predykcje w formacie [x1, y1, x2, y2]
print(f"\nPredykcje dla wybranego obrazu ({chosen_image_path}): {predictions[0][1:]}")

# Obliczanie minimalnego kwadratu błędu (MSE)
mse = mean_squared_error(test_labels, model.predict(test_images))
print(f"\nMinimalny kwadrat błędu (MSE) na zbiorze testowym: {mse}")
